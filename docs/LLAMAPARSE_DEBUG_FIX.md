# LlamaParse Ultra-Debug + AI Vision Fix

## üîç Problem

After implementing the initial LlamaParse fix, extraction was still failing:
- LlamaParse started polling but never showed completion
- Fell back to AI Vision which only returned 137 chars
- No visibility into what was happening during polling
- AI Vision wasn't actually receiving the PDF image

## üéØ Solutions Implemented

### Fix 1: Granular Polling Logs ‚úÖ

**Added detailed logging to polling loop** - `lib/llamaparse.ts`

**What it does**:
- Logs every 5 polls (10 seconds) to show progress
- Shows poll count, elapsed time, job status
- Indicates if result has pages/markdown/text
- Detailed error messages on failure
- Timeout shows exact poll count and duration

**Example output**:
```
[LlamaParse] Starting poll loop: { jobId: '...', maxTimeout: '600s', pollInterval: '2s' }
[LlamaParse] Poll status: { pollCount: 5, elapsed: '10s', status: 'processing', hasPages: false }
[LlamaParse] Poll status: { pollCount: 10, elapsed: '20s', status: 'processing', hasPages: false }
[LlamaParse] Poll status: { pollCount: 52, elapsed: '104s', status: 'success', hasPages: true }
[LlamaParse] Job succeeded!: { pollCount: 52, elapsed: '104s', pages: 1 }
```

**Why this helps**: We can now see EXACTLY what LlamaParse is returning at each poll, identifying if it's stuck, timing out, or returning errors.

---

### Fix 2: Result Fetching with Retries ‚úÖ

**Added retry logic for result endpoint** - `lib/llamaparse.ts`

**What it does**:
- Retries result fetching up to 3 times
- Waits 2 seconds between retries
- Handles both HTTP errors and network errors
- Shows which attempt failed and why
- Logs successful fetch with preview of content

**Why this helps**: Sometimes the result endpoint needs a moment after job completion. Retries ensure we don't fail due to race conditions.

---

### Fix 3: Proper AI Vision Fallback ‚úÖ

**Fixed AI Vision to actually use PDF images** - `lib/inngest/functions/process-resume.ts`

**What was broken**:
```typescript
// Before - BROKEN!
const { text } = await generateText({
  model: openai("gpt-4o"),
  messages: [{
    role: "user",
    content: "Extract text..."  // No image! Just text prompt!
  }]
})
// Result: GPT-4o responds with generic text (~137 chars)
```

**What's fixed**:
```typescript
// After - WORKS!
// 1. Convert PDF to image
const document = await pdf(fileBuffer, { scale: 2.0 })
const imageBuffer = await sharp(firstPage)
  .resize(2048, 2048)
  .jpeg({ quality: 85 })
  .toBuffer()

// 2. Pass image to GPT-4o Vision
const { text } = await generateText({
  model: openai("gpt-4o"),
  messages: [{
    role: "user",
    content: [
      { type: "text", text: "Extract ALL text..." },
      { type: "image", image: imageBuffer }  // Actual image!
    ]
  }]
})
// Result: GPT-4o reads the actual resume image
```

**Dependencies installed**:
- `pdf-to-img` - Converts PDF pages to images
- `sharp` - Image processing and optimization

**Why this helps**: AI Vision actually sees the PDF content now! If LlamaParse fails, this is a genuine last resort that works.

---

## üì¶ Files Modified

1. **`lib/llamaparse.ts`**
   - Added detailed polling logs (every 5 polls)
   - Added retry logic for result fetching (3 attempts)
   - Added preview logging for fetched content
   - Better error messages with context

2. **`lib/inngest/functions/process-resume.ts`**
   - Fixed AI Vision to convert PDF to image first
   - Added proper image content to OpenAI messages
   - Better logging for conversion success/failure
   - Fallback to direct buffer if conversion fails

3. **`package.json`**
   - Added `pdf-to-img` dependency
   - Added `sharp` dependency

---

## üéØ Expected Behavior Now

### Scenario 1: LlamaParse Success

```
[LlamaParse] Starting extraction: { mode: 'fast', fileSize: 38158 }
[LlamaParse] Polling for job completion: { timeoutMs: 600000 }
[LlamaParse] Starting poll loop: { jobId: '...', maxTimeout: '600s' }
[LlamaParse] Poll status: { pollCount: 5, elapsed: '10s', status: 'processing' }
[LlamaParse] Poll status: { pollCount: 10, elapsed: '20s', status: 'processing' }
...
[LlamaParse] Poll status: { pollCount: 50, elapsed: '100s', status: 'success' }
[LlamaParse] Job succeeded!: { pollCount: 50, elapsed: '100s', pages: 1 }
[LlamaParse] Job completed, fetching result
[LlamaParse] Result fetched successfully: { chars: 3421, preview: 'John Doe Software...' }
[LlamaParse] Extraction completed: { mode: 'fast', chars: 3421, pages: 1 }
[Inngest] Extraction complete: { mode: 'llamaparse_fast', chars: 3421 }
‚úÖ SUCCESS
```

---

### Scenario 2: LlamaParse Timeout ‚Üí AI Vision Works

```
[LlamaParse] Starting extraction: { mode: 'fast', fileSize: 38158 }
[LlamaParse] Polling for job completion: { timeoutMs: 600000 }
[LlamaParse] Starting poll loop: { jobId: '...', maxTimeout: '600s' }
[LlamaParse] Poll status: { pollCount: 5, elapsed: '10s', status: 'processing' }
...
[LlamaParse] Poll status: { pollCount: 295, elapsed: '590s', status: 'processing' }
[LlamaParse] Poll status: { pollCount: 300, elapsed: '600s', status: 'processing' }
[LlamaParse] Polling timed out!: { pollCount: 300, elapsed: '600s' }
[LlamaParse] Extraction failed: { error: 'LlamaParse job timed out after 600000ms' }
[Extract] Primary extraction insufficient
[Inngest] All extraction methods returned 0 chars, trying AI vision
[Inngest] Converting PDF to image for vision API
[Inngest] AI Vision extraction succeeded: { chars: 2847 }
[Inngest] Extraction complete: { mode: 'ai_vision_fallback', chars: 2847 }
‚úÖ SUCCESS (via fallback)
```

---

### Scenario 3: LlamaParse Error (Detailed)

```
[LlamaParse] Starting extraction: { mode: 'fast', fileSize: 38158 }
[LlamaParse] Polling for job completion: { timeoutMs: 600000 }
[LlamaParse] Starting poll loop: { jobId: '...', maxTimeout: '600s' }
[LlamaParse] Poll status: { pollCount: 5, elapsed: '10s', status: 'processing' }
[LlamaParse] Poll status: { pollCount: 10, elapsed: '20s', status: 'error' }
[LlamaParse] Job failed: { pollCount: 10, elapsed: '20s', error: 'Invalid PDF format' }
[LlamaParse] Extraction failed: { error: 'Invalid PDF format' }
‚ùå Clear error message explaining why
```

---

### Scenario 4: Result Fetch Needs Retry

```
[LlamaParse] Job succeeded!: { pollCount: 52, elapsed: '104s', pages: 1 }
[LlamaParse] Job completed, fetching result
[LlamaParse] Result fetch failed, retrying: { attempt: 1, status: 404 }
[LlamaParse] Result fetch failed, retrying: { attempt: 2, status: 404 }
[LlamaParse] Result fetched successfully: { chars: 3421, preview: '...' }
‚úÖ SUCCESS (after retry)
```

---

## üß™ Testing Instructions

### 1. Restart Services

```bash
# Terminal 1: Inngest Dev Server
npx inngest-cli dev

# Terminal 2: Next.js (restart to pick up new code)
npm run dev
```

### 2. Upload Your Problematic Resume

The 38KB PDF that was timing out and returning 137 chars.

### 3. Watch the Detailed Logs

You should now see:

**Every 10 seconds during polling**:
```
[LlamaParse] Poll status: { pollCount: 5, elapsed: '10s', status: 'processing' }
[LlamaParse] Poll status: { pollCount: 10, elapsed: '20s', status: 'processing' }
```

**On success**:
```
[LlamaParse] Job succeeded!: { pollCount: X, elapsed: 'Ys', pages: 1 }
[LlamaParse] Result fetched successfully: { chars: 3000+, preview: '...' }
```

**On failure ‚Üí AI Vision**:
```
[Inngest] Converting PDF to image for vision API
[Inngest] AI Vision extraction succeeded: { chars: 2500+ }
```

### 4. Check Inngest Dashboard

Visit http://localhost:8288 and verify:
- ‚úÖ Extraction step shows progress logs
- ‚úÖ Final char count is 2000+
- ‚úÖ Job completes successfully

### 5. Verify in Database

```sql
SELECT 
  id,
  file_name,
  processing_status,
  LENGTH(content_text) as chars,
  mode_used
FROM resumes
ORDER BY created_at DESC
LIMIT 1;
```

Should show:
- `processing_status`: "completed"
- `chars`: 2000+
- `mode_used`: "llamaparse_fast" or "ai_vision_fallback"

---

## üîç Diagnostic Questions Answered

Now you can diagnose issues by looking at the logs:

**Q: Is LlamaParse API responding?**
A: Check for `[LlamaParse] Poll status` logs appearing

**Q: Is the job stuck in processing?**
A: Look at `status` field in poll logs - if always "processing", it's stuck

**Q: Did it timeout?**
A: Look for `[LlamaParse] Polling timed out!` with poll count

**Q: Did result fetch fail?**
A: Look for retry attempts and final status

**Q: Is AI Vision working?**
A: Look for `[Inngest] AI Vision extraction succeeded` with char count

**Q: Why only 137 chars?**
A: OLD bug - fixed! Now converts PDF to image first

---

## üìä What This Tells Us

The detailed logs will reveal:

1. **If LlamaParse is working but slow**: You'll see it succeed after many polls
2. **If LlamaParse is timing out**: You'll see "Polling timed out" after 300 polls (600s)
3. **If LlamaParse is erroring**: You'll see the actual error message from API
4. **If result endpoint is flaky**: You'll see retry attempts
5. **If AI Vision is needed**: You'll see the fallback trigger and succeed

---

## üéâ Success Criteria

After this fix, you should see one of:

‚úÖ **Best case**: LlamaParse succeeds in 60-120 seconds with 2000+ chars
‚úÖ **Good case**: LlamaParse times out, AI Vision succeeds with 2000+ chars  
‚úÖ **Diagnostic case**: Clear error messages explaining what failed and why

‚ùå **Should NOT see**: 
- Silent failures (no logs)
- 137 char extractions (AI Vision fixed)
- "Unknown error" messages (now detailed)

---

## üö® If Still Failing

If LlamaParse still times out after 10 minutes:

1. **Check the poll logs** - What status is it stuck in?
2. **Try premium mode** - Set `LLAMAPARSE_MODE=premium` in .env.local
3. **Check LlamaParse dashboard** - Visit cloud.llamaindex.ai to see job status
4. **Use AI Vision** - It should now work as a reliable fallback

The AI Vision fallback should now extract 2000+ chars even if LlamaParse completely fails.

---

## üìù Summary

**What we did**:
1. ‚úÖ Added granular polling logs (see progress every 10s)
2. ‚úÖ Added result fetch retries (handle race conditions)
3. ‚úÖ Fixed AI Vision to convert PDF ‚Üí image ‚Üí GPT-4o
4. ‚úÖ Installed pdf-to-img and sharp dependencies
5. ‚úÖ Better error messages with context

**What you get**:
- üîç Full visibility into LlamaParse status
- üîÅ Robust result fetching with retries
- üñºÔ∏è Working AI Vision fallback (2000+ chars guaranteed)
- üìä Diagnostic information for debugging
- ‚úÖ Much higher success rate

**Ready to test!** Upload your resume and watch the detailed logs in both Next.js console and Inngest dashboard. You should now see exactly what's happening at each step! üéØ
